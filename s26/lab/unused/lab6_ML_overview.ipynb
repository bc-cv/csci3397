{"cells":[{"cell_type":"markdown","metadata":{"id":"QuUAgQFQlsJU"},"source":["# [CSCI 3397/PSYC 3317] Lab 5: Machine Learning Overview\n","\n","**Posted:** Friday, February 28, 2024\n","\n","**Due:** Wednesday, March 13, 2024\n","\n","__Total Points__: 14 pts\n","\n","__Submission__: please rename the .ipynb file as __\\<your_username\\>_lab5a.ipynb__ before you submit it to canvas. Example: weidf_lab5.ipynb."]},{"cell_type":"markdown","source":["# <b>1. Linear regression</b>"],"metadata":{"id":"Gg4CDwIzcWxk"}},{"cell_type":"code","source":["## utility functions\n","\n","# dataset split\n","def data_split(N, ratio=[6,2,2]):\n","    # generate a shuffle array\n","    shuffle_idx = np.arange(N)\n","    np.random.shuffle(shuffle_idx)\n","    # divide into train-val-test by the ratio\n","    data_split = (np.cumsum(ratio)/float(sum(ratio))*N).astype(int)\n","    out_idx = [None] * len(ratio)\n","    out_idx[0] = shuffle_idx[:data_split[0]]\n","    for i in range(1,len(ratio)):\n","        out_idx[i] = shuffle_idx[data_split[i-1] : data_split[i]]\n","    return out_idx\n","\n","def MSE(y,y_hat):\n","    # Lec. 9, page 19\n","    return ((y-y_hat)**2).mean()"],"metadata":{"id":"l9ORLGH4cXMc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.1 Dataset Generation"],"metadata":{"id":"dzcTQC4Ccgic"}},{"cell_type":"code","source":["# data generation\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","np.random.seed(123)\n","\n","# gt polynomial: y = 0.73x + 0.58\n","theta_gt = [0.58, 0.73]  # theta_0,theta_1\n","num_pt = 50\n","\n","X = np.random.uniform(4, 10, num_pt).reshape(-1,1)\n","Y = theta_gt[0] + theta_gt[1] * X + 0.5 *np.random.normal(0, 1, num_pt).reshape(-1,1)\n","\n","# for visualization\n","XX = np.linspace(4,10,100).reshape(-1,1)\n","\n","train_idx, val_idx, test_idx = data_split(len(Y))\n","\n","X_train, Y_train = X[train_idx], Y[train_idx]\n","X_val, Y_val = X[val_idx], Y[val_idx]\n","X_test, Y_test = X[test_idx], Y[test_idx]\n","\n","plt.plot(X_train,Y_train,'ro')"],"metadata":{"id":"rC4TDb-ichG1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.2 Use 1-dim formula\n","\n","Lec 17, page 20"],"metadata":{"id":"3I9EYtdRch_G"}},{"cell_type":"code","source":["theta_1 = (X_train*Y_train).mean()-X_train.mean()*Y_train.mean()\n","theta_1 = theta_1/ ((X_train**2).mean()-X_train.mean()**2)\n","theta_0 = Y_train.mean()-theta_1*X_train.mean()\n","\n","plt.plot(X_train,Y_train,'ro')\n","plt.plot(XX,XX*theta_1+theta_0,'b-')\n","plt.legend(['data', 'regression result'])\n","\n","print('gt theta', theta_gt)\n","print('estimated theta (1-dim formula)', [theta_0,theta_1])\n","\n","\n","# evaluation on the training data\n","Y_train_hat = X_train*theta_1+theta_0\n","print('MSE error', MSE(Y_train, Y_train_hat))"],"metadata":{"id":"p7vnbuJQciE1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.3 Use N-dim formula\n","\n","Lec 17, page 21"],"metadata":{"id":"aHJbicH2clJQ"}},{"cell_type":"code","source":["X_train_aug = np.hstack([np.ones([len(X_train),1]),X_train])\n","\n","theta_nd = np.linalg.solve(np.matmul(X_train_aug.T, X_train_aug), np.matmul(X_train_aug.T, Y_train))\n","print('estimated theta (N-dim formula)', theta_nd)\n","\n","# evaluation on the training data\n","Y_train_hat = X_train*theta_nd[1]+theta_nd[0]\n","print('MSE error', MSE(Y_train, Y_train_hat))"],"metadata":{"id":"EFkpD5Lvcmt2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# <b>2. Polynomial regression</b>\n","(Linear regression + polynomial feature)"],"metadata":{"id":"ot8NDYGIcrVD"}},{"cell_type":"markdown","source":["## 2.1 Data generation"],"metadata":{"id":"WJtnqo6zcurM"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","np.random.seed(123)\n","\n","# gt polynomial: y = x^2 -10x +25\n","num_pt = 10\n","\n","X2 = np.random.uniform(4, 10, num_pt).reshape(-1,1)\n","theta_gt2 = [25,-10,1]\n","Y2 = theta_gt2[0] + theta_gt2[1]*X2 +theta_gt2[2]*X2**2 + 0.5 *np.random.normal(0, 1, num_pt).reshape(-1,1)\n","\n","# for visualization\n","XX2 = np.linspace(4,10,100).reshape(-1,1)\n","\n","train_idx2, val_idx2, test_idx2 = data_split(len(Y2))\n","\n","X_train2, Y_train2 = X2[train_idx2], Y2[train_idx2]\n","X_val2, Y_val2 = X2[val_idx2], Y2[val_idx2]\n","X_test2, Y_test2 = X2[test_idx2], Y2[test_idx2]\n","\n","plt.plot(X_train2,Y_train2,'ro')"],"metadata":{"id":"HnvqR4aOcvqH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.1 Use N-dim formula\n","\n","Lec 18, page 18"],"metadata":{"id":"Fv3F_sCGcw5F"}},{"cell_type":"code","source":["X_train2_aug = np.hstack([np.ones([len(X_train2),1]),X_train2,X_train2**2])\n","\n","theta_nd2 = np.linalg.solve(np.matmul(X_train2_aug.T, X_train2_aug), np.matmul(X_train2_aug.T, Y_train2))\n","print('gt theta', theta_gt2)\n","print('estimated theta (N-dim formula)',theta_nd2)\n","\n","# evaluation on the training data\n","Y_train2_hat = X_train2 * X_train2 * theta_nd2[2] + X_train2 * theta_nd2[1]+theta_nd2[0]\n","print('MSE error', MSE(Y_train2, Y_train2_hat))"],"metadata":{"id":"OPoGMezNcx_X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1CHRD5GtaN9n"},"source":["# <b>3. Unsupervised learning </b>\n","\n"]},{"cell_type":"markdown","source":["## 3. Data: [[MedMNIST]](https://medmnist.com/)"],"metadata":{"id":"biRjoKVJdaxo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SnSHljE-aN9o"},"outputs":[],"source":["import os\n","if not os.path.exists('pathmnist.npz'):\n","  # download may take 8 min\n","  ! wget https://zenodo.org/record/5208230/files/pathmnist.npz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HIFQRjHUaN9p"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def tensorTo2D(tensor):\n","    # only keep the first dimension: image index\n","    # reshape the rest dimensions into one dimension\n","    return tensor.reshape(tensor.shape[0], -1)\n","\n","data = np.load('pathmnist.npz')\n","X_train = data['train_images'][::10]\n","Y_train = data['train_labels'][::10]\n","X_test = data['test_images'][::10]\n","Y_test = data['test_labels'][::10]\n","\n","# ML assumes 2D input: N x feature input\n","X_train_2d = tensorTo2D(X_train)\n","X_test_2d = tensorTo2D(X_test)\n","\n","num_label = Y_train.max() + 1\n","\n","print('Train data size', X_train.shape)\n","print('Test data size', X_test.shape)\n","ui, uc = np.unique(Y_train, return_counts=True)\n","print('#label', num_label)\n","print('Train label counts', uc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VeICQjqUaN9p"},"outputs":[],"source":["plt.figure(figsize=(12, 12))\n","for i in range(9):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(X_train[i], cmap='gray')\n","    plt.axis('off')\n","    plt.title('class %d' % Y_train[i])"]},{"cell_type":"markdown","metadata":{"id":"fuxIekYOaN9r"},"source":["## 3.1 Clustering\n","Kmeans clustering method:\n","[[Sklearn documentation]](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n","[[Explanation]](https://www.machinecurve.com/index.php/2020/04/16/how-to-perform-k-means-clustering-with-python-in-scikit/)\n","\n","Lec 17, Page 6-10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4hNHhvCcaN9r"},"outputs":[],"source":["# model training\n","from sklearn.cluster import KMeans\n","num_cluster = 5\n","max_iter = 10000\n","kmeans = KMeans(n_clusters = num_cluster, max_iter=max_iter)\n","cluster_labels = kmeans.fit_predict(X_train_2d)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-1Xhea-aN9s"},"outputs":[],"source":["# visualization\n","num_disp = 4\n","plt.figure(figsize=(12, 12))\n","for i in range(num_cluster):\n","    index = np.where(cluster_labels==i)[0]\n","    for j in range(num_disp):\n","        plt.subplot(num_cluster, num_disp, i*num_disp+j+1)\n","        plt.imshow(X_train[index[j]])\n","        plt.axis('off')\n","        if j == 0:\n","            plt.title('cluster %d' % i)"]},{"cell_type":"markdown","metadata":{"id":"HKJUVUMkaN9s"},"source":["## 3.2 Dimension Reduction\n","\n","Principle component analysis (PCA) method:\n","[[Sklearn documentation]](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n","[[Example]](https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html)\n","[[Explanation]](https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c)\n","\n","Lec. 17, Page 11-14"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qu2quVsLaN9s"},"outputs":[],"source":["# model training\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=2)\n","pca.fit(X_train_2d)\n","\n","# inference\n","X_train_pca2 = pca.transform(X_train_2d)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFnQkL9daN9s"},"outputs":[],"source":["# visualization\n","cc='rgbcykm'\n","plt.figure(figsize=(12, 12))\n","for label in range(len(cc)):\n","    index = Y_train[:,0]==label\n","    plt.plot(X_train_pca2[index,0], X_train_pca2[index,1], cc[label]+'.')\n","\n","plt.legend(['cluster %d'%x for x in range(len(cc))])"]},{"cell_type":"markdown","metadata":{"id":"eLZxOOH-lsU3"},"source":["# [14 pts] Exercise"]},{"cell_type":"markdown","source":["## (1) [3 pts] Polynomial regressor for any order of K\n","\n","- [2 pt] Build a function to do polynomial regression with the input order K (e.g., $\\sum_{i=0}^{k}\\theta_ix^i$) and return the estimated theta\n","- [1 pt] Sanity check: for K=2, print the MSE error for the train data (X_train2, Y_train2) in section 2 and check if the MSE values agree."],"metadata":{"id":"Ulz-GwTcc3bq"}},{"cell_type":"code","source":["# hint: create the feature in the beginning and use for-loop to fill in each feature dimension\n","def train_PR(x,y,k):\n","    ### Your code starts here\n","\n","    ### Your code ends here\n","    # retun estimated theta\n","    return theta\n","\n","theta_sanity = train_PR(X_train2, Y_train2, 2)\n","Y_sanity2 = X_train2 * X_train2 * theta_sanity[2] + X_train2 * theta_sanity[1] + theta_sanity[0]\n","print('sanity check MSE:', MSE(Y_train2, Y_sanity2))\n","print('Yes, MSE values agree; MSE is 0.246892141160028 for section 2 and my function.')"],"metadata":{"id":"qPEBE78_c4sq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## (2) [5 pts] Model selection\n","Let `Ks=np.arange(1,11)`\n","- (a) [1 pt] For each K value, train a polynomial regression model with order=K, evaluate its MSE on the training data.\n","- (b) [1 pt] Draw a line-plot of the training MSE (`plt.plot(x,y,'-')`) and answer \"which K shall we choose if the goal is to minimize the training error\"\n","- (c) [1 pt] Evaluate the trained models (different K values) above on the validation data and answer \"which K shall we choose if the goal is to minimize the validation error\"\n","- (d) [1 pt] Repeat (c) on the test data as the \"final/real-world\" evaluation.\n","- (e) [1 pt] Which model selection criteria is better: minimize training error or validation error? Briefly explain why.\n","\n","Lec. 18, slide 30"],"metadata":{"id":"mi1RFk6zc6Fu"}},{"cell_type":"code","source":["### Your code starts here\n","\n","## (a) train poly-K model (save the model parameter in a list) and print MSE\n","\n","\n","## (b) plot MSE vs. K\n","\n","\n","## (c) evaluate the K models above on the validation data\n","\n","\n","\n","## (d) evaluate the K models above on the test data\n","\n","\n","## (e) explain\n","\n","\n","### Your code ends here"],"metadata":{"id":"0sleUhGgc7jM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5p9GU0l9aN9t"},"source":["## (3) [6 pts] Clustering after dimension reduction\n","\n","- [2 pts] repeat section 3 (PCA) for the training data with output dimension=10\n","- [2 pts] repeat section 2 (K-means with K=5) for the 10-dim features above for the training data\n","- [2 pts] Visualize the clustering result as in section 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxMJT2LWaN9t"},"outputs":[],"source":["### Your code starts here\n","\n","## (a) PCA with output dim = 10\n","\n","\n","\n","## (b) k-means on PCA-transformed X_train with K=5\n","\n","\n","## (c) visualize clustering result\n","\n","\n","### Your code ends here"]}],"metadata":{"colab":{"provenance":[{"file_id":"1_d49_U8Zrz_Ac-QWgXFBzr4CJ4S8fKe1","timestamp":1614174979410}],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}